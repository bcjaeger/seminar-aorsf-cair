{
  "hash": "a4e965bcb2d0a27a5fa573b75e71ebb5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Oblique Random Forests\"\nsubtitle: \"Making Leo Breimanâ€™s Masterpiece Accessible and Interpretable with `aorsf`\"\nauthor: \"Byron C Jaeger\"\ndate: \"February 19, 2025\"\nformat: \n  revealjs:\n    theme: simple\n    css: custom.css\n    slide-number: true\nexecute: \n  freeze: auto\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n## Hello, my name is Byron\n\n![](img/run_R_kids.png){fig-align=\"center\"}\n\n## Bottom line up front\n\n1. Oblique random forests are good at prediction, and they are *excellent* tools for spectral data (defined later).\n\n1. `aorsf` provides a unified, simple, and fast interface for oblique random forests.\n\n## Slides\n\nAvailable online: \n\n- [https://www.byronjaeger.com/talk](https://www.byronjaeger.com/talk)\n\n- Google \"Byron Jaeger talk\"\n\n## Overview\n\n- Background\n\n    + Supervised learning\n    \n    + Decision trees and random forests\n\n- Oblique random forests\n\n    + What is oblique?\n\n    + `aorsf` statement of need\n    \n    + `aorsf` demo\n\n# Supervised learning\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-1-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-1-2.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-1-3.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-2.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-3.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-4.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-5.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-6.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-7.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-7-1.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/ml-supervised-7-2.svg){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n## Learners\n\n\nA *learner* is a recipe for a prediction model\n\n:::{.incremental}\n\n- A learner is not the same thing as a prediction model \n\n- A recipe is not the same thing as food.\n\n- This distinction is important for cross-validation (defined soon)\n\n:::\n\n---\n\n## Find a good learner for these data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Learner 1: find the line of best fit\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Learner 1: find the line of best fit\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Learner 2: Use a spline\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Learner 3: Loosen the spline\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Cross validation\n\nThis technique allows you to objectively compare *learners*\n\n:::{.incremental}\n\n- Hold some data out as a testing set\n\n- Apply each learner to the remaining data (training set)\n\n- Predict the outcome using each model (one per learner)\n\n- Evaluate prediction accuracy\n\n- Repeat with different held out data\n\n- Compare average prediction accuracy by learner\n\n:::\n\n---\n\n## All our data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Select a testing set\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Take it away\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-20-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Apply learner 1\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-21-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n\n## Apply learner 2\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-22-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n---\n\n## Apply learner 3\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-23-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Assess predictions in testing data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-24-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Assess predictions in testing data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-25-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Assess predictions in testing data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-26-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\n## Assess predictions in testing data\n\n- Cross-validation highlights learners that overfit.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"xofdizgqou\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#xofdizgqou table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#xofdizgqou thead, #xofdizgqou tbody, #xofdizgqou tfoot, #xofdizgqou tr, #xofdizgqou td, #xofdizgqou th {\n  border-style: none;\n}\n\n#xofdizgqou p {\n  margin: 0;\n  padding: 0;\n}\n\n#xofdizgqou .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 35px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: 100%;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#xofdizgqou .gt_title {\n  color: #333333;\n  font-size: 35px;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#xofdizgqou .gt_subtitle {\n  color: #333333;\n  font-size: 35px;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#xofdizgqou .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 35px;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#xofdizgqou .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 35px;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#xofdizgqou .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#xofdizgqou .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#xofdizgqou .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#xofdizgqou .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#xofdizgqou .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 35px;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#xofdizgqou .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 35px;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#xofdizgqou .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#xofdizgqou .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#xofdizgqou .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#xofdizgqou .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 35px;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xofdizgqou .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#xofdizgqou .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#xofdizgqou .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#xofdizgqou .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xofdizgqou .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#xofdizgqou .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xofdizgqou .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#xofdizgqou .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xofdizgqou .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#xofdizgqou .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#xofdizgqou .gt_left {\n  text-align: left;\n}\n\n#xofdizgqou .gt_center {\n  text-align: center;\n}\n\n#xofdizgqou .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#xofdizgqou .gt_font_normal {\n  font-weight: normal;\n}\n\n#xofdizgqou .gt_font_bold {\n  font-weight: bold;\n}\n\n#xofdizgqou .gt_font_italic {\n  font-style: italic;\n}\n\n#xofdizgqou .gt_super {\n  font-size: 65%;\n}\n\n#xofdizgqou .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#xofdizgqou .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#xofdizgqou .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#xofdizgqou .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#xofdizgqou .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#xofdizgqou .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#xofdizgqou .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#xofdizgqou .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#xofdizgqou div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"a::stub\">Learner</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"rmse_train\">Training error</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"rmse_test\">Testing error</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><th id=\"stub_1_1\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Line</th>\n<td headers=\"stub_1_1 rmse_train\" class=\"gt_row gt_center\">0.41</td>\n<td headers=\"stub_1_1 rmse_test\" class=\"gt_row gt_center\">0.34</td></tr>\n    <tr><th id=\"stub_1_2\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Spline</th>\n<td headers=\"stub_1_2 rmse_train\" class=\"gt_row gt_center\">0.28</td>\n<td headers=\"stub_1_2 rmse_test\" class=\"gt_row gt_center\">0.22</td></tr>\n    <tr><th id=\"stub_1_3\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Loose spline</th>\n<td headers=\"stub_1_3 rmse_train\" class=\"gt_row gt_center\">0.27</td>\n<td headers=\"stub_1_3 rmse_test\" class=\"gt_row gt_center\">0.35</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n# Decision trees and random forests\n\n---\n\n![](img/penguins.png){width=100%}\n\n:::footer\nData were collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the Palmer Station, a member of the [Long Term Ecological Research Network](https://lternet.edu/).\n:::\n\n\n---\n\nDecision trees grow by recursively splitting data.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-28-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nSplits should create groups with different outcomes.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-29-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nSplitting continues until stopping criterion are met.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-30-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nThe same splits, visualized as a tree\n\n![](img/rpart_plot_classif.png){fig-align=\"center\"}\n\n\n---\n\n## Decision trees\n\n- Pros\n\n    + Simple and intuitive visualization.\n    \n    + Captures conditional relationships.\n\n- Cons\n\n    + Difficulty with linear relationships.\n    \n    + Overfits when trees grow too deep.\n\n## Random forests\n\nDefn: an ensemble of de-correlated decision trees\n\n:::{.incremental}\n\n- Each tree on its own is fairly weak at prediction.\n\n- However, the aggregate prediction is usually very good.\n\n- Why? Consider this example\n\n\n\n  ::: {.cell layout-align=\"center\"}\n  \n  ```{.r .cell-code}\n  # suppose we ask 5000 independent weak learners a yes/no question.\n  # Individually, weak learners are right 51% of the time. However,\n  # the probability that a majority of weak learners are right is 92%.\n  # proof:\n  1 - pbinom(q = 2500, size = 5000, prob = 0.51)\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  \n  ```\n  [1] 0.9192858\n  ```\n  \n  \n  :::\n  :::\n\n\n\n:::\n\n## Random forests\n\nDefn: an ensemble of de-correlated decision trees\n\n- Each tree on its own is fairly weak at prediction.\n\n- However, the aggregate prediction is usually very good.\n\n- How are they de-correlated? \n\n    + Random subset of (bootstrapped) data for each tree.\n    \n    + Random subset of predictors considered for each split.\n\n---\n\nPredictions from a single randomized tree\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-31-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nPredictions from ensemble of 5 randomized trees\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-32-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nPredictions from ensemble of 100 randomized trees\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-33-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nPredictions from ensemble of 500 randomized trees\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-34-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n# Oblique random forests\n\n## What is oblique?\n\n![](img/axis_versus_oblique.png){fig-align=\"center\"}\n\n---\n\nPredictions from a single oblique tree\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-35-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n---\n\nPredictions from an oblique random forest\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-36-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Are oblique splits helpful?\n\nFor **prediction**, the answer is **usually yes**.\n\n- Leo Breiman, author of the random forest, noted this:\n\n![](img/axis_versus_oblique_leo.png){fig-align=\"center\"}\n\n- This result has been replicated in multiple studies:\n\n    + [Menze et al](https://link.springer.com/chapter/10.1007/978-3-642-23783-6_29), [Katuwal et al](https://www.sciencedirect.com/science/article/abs/pii/S0031320319303796), [Tomita et al](https://jmlr.org/papers/v21/18-664.html), and [Jaeger et al](https://pmc.ncbi.nlm.nih.gov/articles/PMC11343578/)\n\n- Evidence on [consistency](https://arxiv.org/html/2211.12653v4#S6) of oblique trees is emerging.\n\n## Are oblique splits helpful?\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\nFor **computational efficiency**, the answer is **no**.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata_bench <- as.data.frame(\n mutate(drop_na(penguins), species=factor(species))\n)\n\nbench <- microbenchmark(\n axis_ranger = ranger(formula = species ~ bill_length_mm + flipper_length_mm, \n                      data = data_bench),\n axis_rfsrc = rfsrc(formula = species ~ bill_length_mm + flipper_length_mm,\n                    data = data_bench),\n oblique_aorsf = orsf(formula = species ~ bill_length_mm + flipper_length_mm, \n                      data = data_bench),\n oblique_odrf = ODRF(formula = species ~ bill_length_mm + flipper_length_mm, \n                     data = data_bench),\n times = 10\n)\n```\n:::\n\n\n\n## Are oblique splits helpful?\n\n\nFor **computational efficiency**, the answer is **no**.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprint(bench, signif=3, unit='relative')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnit: relative\n          expr    min     lq   mean median      uq    max neval cld\n   axis_ranger   1.00   1.00   1.00   1.00   1.000   1.00    10  a \n    axis_rfsrc   1.78   1.77   1.22   1.75   0.732   1.08    10  a \n oblique_aorsf   1.57   1.96   1.43   1.93   0.920   1.39    10  a \n  oblique_odrf 554.00 530.00 291.00 463.00 174.000 134.00    10   b\n```\n\n\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n:::{.columns}\n::: {.column width=\"60%\"}\n\n<h2 style=\"font-size: 60px;\">\n    Computational efficiency is important\n</h2>\n\n30-day downloads from CRAN:\n\n- axis-based packages:\n\n    + `ranger`: 42,012\n\n    + `randomForestSRC`: 5,388\n\n- oblique packages:\n\n    + `aorsf`: 1,470\n\n    + `ODRF`: 264\n\n\n:::\n\n::: {.column width=\"40%\"}\n![](img/meme_slow_R.jpg){fig-align=\"right\"}\n:::\n:::\n\n\n\n# `aorsf`\n\n---\n\n## Statement of need\n\n:::{.incremental}\n\n- Oblique random forests are under-utilized, with high computational cost. Existing software focus on specific implementations, limiting scope.\n\n- `aorsf` is unifying oblique random forest software.\n\n    + Fast C++ backend based on `ranger`.\n    + Supports survival, regression, and classification.\n    + Supports custom functions for oblique splitting.\n    + Part of `tidymodels` and `mlr3`.\n    + Fast variable importance and partial dependence.\n\n:::\n\n## \"a\" stands for \"accelerated\"\n\nOur approach for linear combinations of predictors:\n\n- Fit a regression model to data in the current tree node\n\n    + Note: logistic and Cox models iterate until converging\n\n- Instead of iterating until convergence, stop after one.\n\n- Use the beta coefficients from the model as coefficients for the linear combination of predictors.\n\n## Demo with spectral data\n\nSpectral data include continuous, correlated predictors.\n\n- Example: `modeldata::meats`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| protein|   x_001|   x_002|... |   x_100|\n|-------:|-------:|-------:|:---|-------:|\n|    16.7| 2.61776| 2.61814|... | 2.81920|\n|    13.5| 2.83454| 2.83871|... | 3.17942|\n|    20.5| 2.58284| 2.58458|... | 2.54816|\n|    20.7| 2.82286| 2.82460|... | 2.79622|\n\n\n:::\n:::\n\n\n\n## Demo with spectral data\n\n- *Description*: Data are recorded on a Tecator Infratec Food and Feed Analyzer working in the wavelength range 850 - 1050 nm by the Near Infrared Transmission principle. Each sample contains finely chopped pure meat with different moisture, fat and protein contents\n\n- *Details*: For each meat sample the data consists of a 100 channel spectrum of absorbances and the contents of moisture (water), fat and protein. The absorbance is -log10 of the transmittance measured by the spectrometer. The three contents, measured in percent, are determined by analytic chemistry\n\n---\n\n## Demo with spectral data\n\n:::{.columns}\n::: {.column width=\"50%\"}\n\nMake train & test sets:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntrn_rows <- \n sample(nrow(meats), 100)\n\nmeats_train <- meats[trn_rows, ]\n\nmeats_test <- meats[-trn_rows, ]\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\nTrain axis & oblique forests:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_aorsf <- \n orsf(protein ~ ., \n      data = meats_train)\nfit_ranger <- \n ranger(protein ~.,\n        data = meats_train)\n```\n:::\n\n\n\n:::\n\n:::\n\nEvaluate $R^2$ of predictions (higher is better):\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprd_aorsf <- predict(fit_aorsf, new_data = meats_test, pred_simplify = T)\nprd_ranger <- predict(fit_ranger, data = meats_test)$predictions\n\nrsq_vec(estimate = prd_aorsf, truth = meats_test$protein)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9356059\n```\n\n\n:::\n\n```{.r .cell-code}\nrsq_vec(estimate = prd_ranger, truth = meats_test$protein)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6872002\n```\n\n\n:::\n:::\n\n\n\n## Demo with spectral data\n\n\n`aorsf` supports variable importance\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\norsf_vi(fit_aorsf)[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      fat     x_029     x_028 \n0.2355890 0.2328767 0.2315789 \n```\n\n\n:::\n:::\n\n\n\nAnd multivariable-adjusted summaries for each predictor:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\norsf_summarize_uni(fit_aorsf, n_variables = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n-- fat (VI Rank: 1) ------------------------\n\n        |--------- Expected value ---------|\n  Value     Mean   Median   25th %   75th %\n <char>    <num>    <num>    <num>    <num>\n   5.90 18.29500 19.33016 16.37537 20.19645\n   7.28 18.27809 19.32573 16.36435 20.17653\n   15.7 18.12412 19.20343 16.31901 19.95582\n   29.2 17.88790 18.98651 15.98738 19.70517\n   37.9 17.75646 18.84186 15.91031 19.60750\n\n Predicted expected value for top 1 predictors \n```\n\n\n:::\n:::\n\n\n\n## Demo with spectral data\n\n`aorsf` can also look for pairwise interactions (details [here](https://arxiv.org/abs/1805.04755))\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntop_preds <- names(orsf_vi(fit_aorsf)[1:10])\n\n# warning: this can get very computationally expensive.\n# use subsets of <= 10 predictors to keep it efficient.\nvint <- orsf_vint(fit_aorsf, predictors = top_preds)\n\nvint[1:10, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     interaction       score          pd_values\n          <char>       <num>             <list>\n 1: x_029..x_014 0.010221001 <data.table[25x9]>\n 2: x_030..x_035 0.010012501 <data.table[25x9]>\n 3: x_029..x_034 0.008032039 <data.table[25x9]>\n 4: x_028..x_014 0.008020588 <data.table[25x9]>\n 5: x_034..x_026 0.007513260 <data.table[25x9]>\n 6: x_034..x_035 0.007083606 <data.table[25x9]>\n 7: x_029..x_035 0.006955590 <data.table[25x9]>\n 8: x_030..x_014 0.006674831 <data.table[25x9]>\n 9: x_027..x_014 0.006570676 <data.table[25x9]>\n10: x_034..x_030 0.006246572 <data.table[25x9]>\n```\n\n\n:::\n:::\n\n\n\n## Demo with spectral data\n\nand sometimes it finds them.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-48-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Demo with spectral data\n\nSanity check the result using regression\n\n::: {.columns}\n::: {.column width=\"55%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(\n lm(\n  protein ~ bs(x_029)*bs(x_014), \n  data = meats_train\n )\n)\n\nanova(\n lm(\n  protein ~ bs(x_030)*bs(x_035),\n  data = meats_train\n )\n)\n```\n:::\n\n\n\n:::\n\n::: {.column width=\"45%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 Ã— 2\n  term                p.value\n  <chr>               <chr>  \n1 bs(x_029)           <.001  \n2 bs(x_014)           <.001  \n3 bs(x_029):bs(x_014) <.001  \n4 Residuals           --     \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 Ã— 2\n  term                p.value\n  <chr>               <chr>  \n1 bs(x_030)           <.001  \n2 bs(x_035)           <.001  \n3 bs(x_030):bs(x_035) .20    \n4 Residuals           --     \n```\n\n\n:::\n:::\n\n\n\n:::\n:::\n\n## More spectral data\n\n- Here is a much larger spectral data example\n\n- Example: `modeldatatoo::data_chimiometrie_2019()`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6,915 Ã— 7\n   soy_oil wvlgth_001 wvlgth_002 wvlgth_003 wvlgth_004 ...   wvlgth_550\n     <dbl>      <dbl>      <dbl>      <dbl>      <dbl> <chr>      <dbl>\n 1     2.1      0.208      0.207      0.207      0.207 ...        0.592\n 2     2.1      0.206      0.206      0.206      0.206 ...        0.600\n 3     2.1      0.207      0.207      0.207      0.206 ...        0.602\n 4     0.5      0.206      0.206      0.205      0.205 ...        0.608\n 5     0.5      0.201      0.200      0.200      0.200 ...        0.601\n 6     0.5      0.206      0.205      0.205      0.205 ...        0.613\n 7     0.5      0.202      0.202      0.201      0.201 ...        0.614\n 8     0.5      0.205      0.205      0.204      0.204 ...        0.585\n 9     0.5      0.205      0.205      0.204      0.204 ...        0.594\n10     0.5      0.207      0.207      0.207      0.207 ...        0.589\n# â„¹ 6,905 more rows\n```\n\n\n:::\n:::\n\n\n\n## More spectral data\n\n- *Description*: This data set was published as the challenge at the Chimiometrie 2019 conference held in Montpellier and is available at the conference homepage. The data consist of 6915 training spectra and 600 test spectra measured at 550 (unknown) wavelengths. The target was the amount of soy oil (0-5.5%), ucerne (0-40%) and barley (0-52%) in a mixture\n\n## Bigger benchmark\n\nNow we'll fit 6 learners in addition to `aorsf` and use nested cross-validation to tune each approach, including:\n\n- consider 16 data pre-processing approaches (details [here](https://github.com/bcjaeger/tidymodel-bench/blob/9bedfb9c51f4d6e3615fa89ac0decacae21a0038/run_nested_cv.R#L133))\n\n    + includes option for each learner to use a variable selection step and data transformation (i.e., principal component analysis)\n\n- implement tuning for each learner (details [here](https://github.com/bcjaeger/tidymodel-bench/blob/9bedfb9c51f4d6e3615fa89ac0decacae21a0038/R/initialize.R#L127))\n\nAll code available [here](https://github.com/bcjaeger/tidymodel-bench/)\n\n---\n\nEven with fully developed tuning pipelines, it is difficult to beat oblique random forests in spectral data.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-52-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Conclusion\n\n1. Oblique random forests are good at prediction, and they are *excellent* tools for spectral data.\n\n1. `aorsf` provides a unified, simple, and fast interface for oblique random forests.\n\n1. Learn more [here](https://docs.ropensci.org/aorsf/)\n\n# Thank you!\n\n# Bonus round\n\n---\n\nSubsetting data by tree allows for out-of-bag prediction.\n\n![](img/trees-oobag-1.svg){width=100%}\n\n---\n\nAbout 2/3 of the data are in-bag for each tree.\n\n![](img/trees-oobag-2.svg){width=100%}\n\n---\n\n\nThe out-of-bag remainder is external to the tree.\n\n![](img/trees-oobag-3.svg){width=100%}\n\n---\n\nEach observation's denominator is tracked\n\n![](img/trees-oobag-4.svg){width=100%}\n\n---\n\nRepeat until all trees are grown.\n\n![](img/trees-oobag-5.svg){width=100%}\n\n## Why out-of-bag predictions matter\n\nThey are almost as important as the random forest itself\n\n1. Unbiased assessment of external prediction accuracy.\n\n2. The basis for computing permutation variable importance.\n\n3. A necessity for consistency of causal random forests.\n\nAs a bonus, assessing out-of-bag prediction accuracy is also much faster than cross-validation.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}